{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4264799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver import Chrome \n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.common.by import By \n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# initialize a headless web scraper\n",
    "\n",
    "options = webdriver.ChromeOptions() \n",
    "options.headless = True \n",
    "options.page_load_strategy = 'none' \n",
    "\n",
    "chrome_path = ChromeDriverManager().install() \n",
    "chrome_service = Service(chrome_path) \n",
    "\n",
    "driver = Chrome(options=options, service=chrome_service) \n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "# local path names\n",
    "\n",
    "LINKS_PATH = 'links.txt'\n",
    "DATA_PATH  = 'optimism/data/projects/'\n",
    "\n",
    "\n",
    "# module for extracting fields from a given project page\n",
    "def extract_fields(link):\n",
    "\n",
    "    driver.get(link)\n",
    "    content = driver.find_element(By.CSS_SELECTOR, \"div[class^='_content'\")\n",
    "    project = content.find_element(By.CSS_SELECTOR, \"h1[class^='_header'\").text\n",
    "    socials = [s.get_property(\"href\")\n",
    "               for s in content.find_elements(By.CSS_SELECTOR, \"a[class^='_socialLink'\")]\n",
    "    responses = content.find_elements(By.TAG_NAME, \"section\")\n",
    "    description = responses[0].find_element(By.TAG_NAME, \"p\").text\n",
    "    category = responses[1].find_element(By.CSS_SELECTOR, \"span[class^='_label'\").text\n",
    "    address = content.find_element(By.CSS_SELECTOR, \"div[class^=_addressWrapper'\").text\n",
    "    p_grabber = lambda r: \"\\n\".join([t.text for t in r.find_elements(By.TAG_NAME, \"p\")])\n",
    "    logo = driver.find_element(By.CSS_SELECTOR, \"img[class^='_image'\").get_property(\"src\")\n",
    "    try:\n",
    "        banner = (driver\n",
    "                  .find_element(By.CSS_SELECTOR, \"div[class^='_banner'\")\n",
    "                  .find_element(By.TAG_NAME, \"img\").get_property(\"src\"))\n",
    "    except:\n",
    "        banner = None\n",
    "    \n",
    "    return {\n",
    "        'project': project,\n",
    "        'socials': socials,\n",
    "        'description': description,\n",
    "        'category': category,\n",
    "        'public_goods': p_grabber(responses[2]),\n",
    "        'sustainability': p_grabber(responses[3]),\n",
    "        'team_size': p_grabber(responses[4]),\n",
    "        'address': address,\n",
    "        'banner': banner,\n",
    "        'logo': logo        \n",
    "    }\n",
    "\n",
    "\n",
    "# process each link and store the data\n",
    "def process_url(link):\n",
    "\n",
    "    result = extract_fields(link)    \n",
    "    result.update({'project_link': link})\n",
    "    result.update({'project_pathname': link.split(\"/\")[-1]})\n",
    "    \n",
    "    j = json.dumps(result, indent=4)\n",
    "    outpath = f\"{DATA_PATH}{result['project_pathname']}.json\"\n",
    "    with open(outpath, \"w\") as outfile:\n",
    "        outfile.write(j)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# read and process all links\n",
    "def scrape_all_projects():\n",
    "\n",
    "    with open(LINKS_PATH, 'r') as txt_file:\n",
    "        links = [f.strip() for f in txt_file.readlines()]\n",
    "\n",
    "    for project_url in links:\n",
    "        #time.sleep(2)\n",
    "        try:\n",
    "            result = process_url(project_url)         \n",
    "            print(\"✅ Scraped: \", result['project'])\n",
    "        except:\n",
    "            print(\"❌ Error:\", project_url)  \n",
    "\n",
    "\n",
    "scrape_all_projects()           \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33bbfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
